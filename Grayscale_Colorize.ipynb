{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grayscale_Colorize",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrGS7X0eRtEZ"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkQsHOPFSGRA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from functools import reduce\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3IukWRSV1U"
      },
      "source": [
        "class shave_block(nn.Module):\n",
        "    def __init__(self, s):\n",
        "        super(shave_block, self).__init__()\n",
        "        self.s=s\n",
        "    def forward(self,x):\n",
        "        return x[:,:,self.s:-self.s,self.s:-self.s]\n",
        "\n",
        "class LambdaBase(nn.Sequential):\n",
        "    def __init__(self, fn, *args):\n",
        "        super(LambdaBase, self).__init__(*args)\n",
        "        self.lambda_func = fn\n",
        "\n",
        "    def forward_prepare(self, input):\n",
        "        output = []\n",
        "        for module in self._modules.values():\n",
        "            output.append(module(input))\n",
        "        return output if output else input\n",
        "\n",
        "class Lambda(LambdaBase):\n",
        "    def forward(self, input):\n",
        "        return self.lambda_func(self.forward_prepare(input))\n",
        "\n",
        "class LambdaMap(LambdaBase):\n",
        "    def forward(self, input):\n",
        "        return list(map(self.lambda_func,self.forward_prepare(input)))\n",
        "\n",
        "class LambdaReduce(LambdaBase):\n",
        "    def forward(self, input):\n",
        "        return reduce(self.lambda_func,self.forward_prepare(input))\n",
        "\n",
        "def generator():\n",
        "    # Conv2d(in_channels, out_channels, filter_size, stride=(1,1), padding=(0,0))\n",
        "    G = nn.Sequential( # Sequential,\n",
        "        nn.ReflectionPad2d((40, 40, 40, 40)),\n",
        "        nn.Conv2d(1,32,(9, 9),(1, 1),(4, 4)),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,(3, 3),(2, 2),(1, 1)),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,128,(3, 3),(2, 2),(1, 1)),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Sequential( # Sequential,\n",
        "            LambdaMap(lambda x: x, # ConcatTable,\n",
        "                nn.Sequential( # Sequential,\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    ),\n",
        "                shave_block(2),\n",
        "                ),\n",
        "            LambdaReduce(lambda x,y: x+y), # CAddTable,\n",
        "            ),\n",
        "        nn.Sequential( # Sequential,\n",
        "            LambdaMap(lambda x: x, # ConcatTable,\n",
        "                nn.Sequential( # Sequential,\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    ),\n",
        "                shave_block(2),\n",
        "                ),\n",
        "            LambdaReduce(lambda x,y: x+y), # CAddTable,\n",
        "            ),\n",
        "        nn.Sequential( # Sequential,\n",
        "            LambdaMap(lambda x: x, # ConcatTable,\n",
        "                nn.Sequential( # Sequential,\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    ),\n",
        "                shave_block(2),\n",
        "                ),\n",
        "            LambdaReduce(lambda x,y: x+y), # CAddTable,\n",
        "            ),\n",
        "        nn.Sequential( # Sequential,\n",
        "            LambdaMap(lambda x: x, # ConcatTable,\n",
        "                nn.Sequential( # Sequential,\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    ),\n",
        "                shave_block(2),\n",
        "                ),\n",
        "            LambdaReduce(lambda x,y: x+y), # CAddTable,\n",
        "            ),\n",
        "        nn.Sequential( # Sequential,\n",
        "            LambdaMap(lambda x: x, # ConcatTable,\n",
        "                nn.Sequential( # Sequential,\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Conv2d(128,128,(3, 3)),\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    ),\n",
        "                shave_block(2),\n",
        "                ),\n",
        "            LambdaReduce(lambda x,y: x+y), # CAddTable,\n",
        "            ),\n",
        "        nn.ConvTranspose2d(128,64,(3, 3),(2, 2),(1, 1),(1, 1)),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(64,32,(3, 3),(2, 2),(1, 1),(1, 1)),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,2,(9, 9),(1, 1),(4, 4)),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "    return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLMVvnEOSbVT"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfcu7e85TYTX"
      },
      "source": [
        "import torchvision.models as models\n",
        "import os\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2yuv,yuv2rgb\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esuv2V2NUoF2"
      },
      "source": [
        "# define data generator\n",
        "class img_data(data.Dataset):\n",
        "    def __init__(self, path):\n",
        "        files = os.listdir(path)\n",
        "        self.files = [os.path.join(path,x) for x in files]\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index])\n",
        "        yuv = rgb2yuv(img)\n",
        "        y = yuv[...,0]-0.5\n",
        "        u_t = yuv[...,1] / 0.43601035\n",
        "        v_t = yuv[...,2] / 0.61497538\n",
        "        # Put these values in a standard Tensor\n",
        "        return torch.Tensor(np.expand_dims(y,axis=0)),torch.Tensor(np.stack([u_t,v_t],axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0mOEQ5WeGN"
      },
      "source": [
        "checkpoint_location = \"drive/MyDrive/Grayscale_Colorize/checkpoints\"\n",
        "training_dir = \"drive/MyDrive/Grayscale_Colorize/places365\"\n",
        "test_image = \"drive/MyDrive/Grayscale_Colorize/test_img.jpg\"\n",
        "# The various Hyperparameters\n",
        "pixel_loss_weights = 1000.0\n",
        "# Number of times to go through over complete dataset\n",
        "epochs = 65\n",
        "# On Google Colab, we can use very powerful GPUs like the NVIDIA P-1000\n",
        "gpu = 0\n",
        "# We load images in RAM in batches\n",
        "batch_size = 20\n",
        "# Number of parallel threads\n",
        "num_workers = 6\n",
        "# Gradient is calculated after every batch's processing and backpropagated\n",
        "g_every = 1\n",
        "# Learning rate for generator\n",
        "g_lr = 1e-4\n",
        "# Learning rate for discriminator\n",
        "d_lr = 1e-4\n",
        "# Checkpoints saved to disk every 100 iterations\n",
        "checkpoint_every = 100\n",
        "# Initial weights for discriminator\n",
        "d_init = \"drive/MyDrive/Grayscale_Colorize/D_init.pth\"\n",
        "# Initial weights for Generator\n",
        "g_init = \"drive/MyDrive/Grayscale_Colorize/G_init.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHHt11pZUxNF"
      },
      "source": [
        "if not os.path.exists(os.path.join(checkpoint_location,'weights')):\n",
        "    os.makedirs(os.path.join(checkpoint_location,'weights'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGO0p_goVawW"
      },
      "source": [
        "# Define G, same as torch version\n",
        "G = generator().cuda(gpu)\n",
        "\n",
        "# define D, 2 classes -> Real or Fake\n",
        "D = models.resnet18(pretrained=False, num_classes=2)\n",
        "# Add a fully connected layer\n",
        "# Apply a linear transformation to the incoming data: y = xA^T + b\n",
        "# Rescaled to 512 * 512\n",
        "D.fc = nn.Sequential(nn.Linear(512, 1), nn.Sigmoid())\n",
        "D = D.cuda(gpu)\n",
        "\n",
        "trainset = img_data(training_dir)\n",
        "params = {'batch_size': batch_size,\n",
        "          'shuffle': True,\n",
        "          'num_workers': num_workers}\n",
        "training_generator = data.DataLoader(trainset, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0f0EMAVrZt"
      },
      "source": [
        "if test_image is not None:\n",
        "    test_img = Image.open(test_image).convert('RGB').resize((256,256))\n",
        "    test_yuv = rgb2yuv(test_img)\n",
        "    # Expand dimensions / make it linear\n",
        "    test_inf = test_yuv[...,0].reshape(1,1,256,256)\n",
        "    test_var = Variable(torch.Tensor(test_inf-0.5)).cuda(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqwgcV1UVtgA"
      },
      "source": [
        "# Load the initial weights\n",
        "if d_init is not None:\n",
        "    D.load_state_dict(torch.load(d_init, map_location='cuda:0'))\n",
        "if g_init is not None:\n",
        "    G.load_state_dict(torch.load(g_init, map_location='cuda:0'))\n",
        "\n",
        "print(\"Initial Weights Loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko36ZUq3V29h"
      },
      "source": [
        "if test_image is not None:\n",
        "    test_res = G(test_var)\n",
        "    uv=test_res.cpu().detach().numpy()\n",
        "    uv[:,0,:,:] *= 0.436\n",
        "    uv[:,1,:,:] *= 0.615\n",
        "    test_yuv = np.concatenate([test_inf,uv],axis=1).reshape(3,256,256)\n",
        "    test_rgb = yuv2rgb(test_yuv.transpose(1,2,0))\n",
        "    cv2.imwrite(os.path.join(checkpoint_location,'test_init.jpg'),(test_rgb.clip(min=0,max=1)*256)[:,:,[2,1,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KE_wVM9WSuG"
      },
      "source": [
        "i=0\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "optimizer_G = torch.optim.Adam(G.parameters(), lr=g_lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(D.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
        "for epoch in range(17,epochs):\n",
        "    for y, uv in training_generator:\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(torch.Tensor(y.size(0), 1).fill_(1.0), requires_grad=False).cuda(gpu)\n",
        "        # Black and white version with fill 0\n",
        "        fake = Variable(torch.Tensor(y.size(0), 1).fill_(0.0), requires_grad=False).cuda(gpu)\n",
        "\n",
        "        yvar = Variable(y).cuda(gpu)\n",
        "        uvvar = Variable(uv).cuda(gpu)\n",
        "        real_imgs = torch.cat([yvar,uvvar],dim=1)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        uvgen = G(yvar)\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = torch.cat([yvar.detach(),uvgen],dim=1)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss_gan = adversarial_loss(D(gen_imgs), valid)\n",
        "        g_loss = g_loss_gan + pixel_loss_weights * torch.mean((uvvar-uvgen)**2)\n",
        "        if i%g_every==0:\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(D(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(D(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "        i+=1\n",
        "        if i%checkpoint_every==0:\n",
        "            print (\"Epoch: %d: [D loss: %f] [G total loss: %f] [G GAN Loss: %f]\" % (epoch, d_loss.item(), g_loss.item(), g_loss_gan.item()))\n",
        "\n",
        "            torch.save(D.state_dict(), os.path.join(checkpoint_location,'weights','D'+str(epoch)+'.pth'))\n",
        "            torch.save(G.state_dict(), os.path.join(checkpoint_location,'weights','G'+str(epoch)+'.pth'))\n",
        "            if test_image is not None:\n",
        "                test_res = G(test_var)\n",
        "                uv=test_res.cpu().detach().numpy()\n",
        "                uv[:,0,:,:] *= 0.436\n",
        "                uv[:,1,:,:] *= 0.615\n",
        "                test_yuv = np.concatenate([test_inf,uv],axis=1).reshape(3,256,256)\n",
        "                test_rgb = yuv2rgb(test_yuv.transpose(1,2,0))\n",
        "                cv2.imwrite(os.path.join(checkpoint_location,'test_epoch_'+str(epoch)+'.jpg'),(test_rgb.clip(min=0,max=1)*256)[:,:,[2,1,0]])\n",
        "torch.save(D.state_dict(), os.path.join(checkpoint_location,'D_final.pth'))\n",
        "torch.save(G.state_dict(), os.path.join(checkpoint_location,'G_final.pth'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiSSJQ8ij6HD"
      },
      "source": [
        "# Colorize new Grayscale Images using the Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVjBgT2AQY5M"
      },
      "source": [
        "from scipy.ndimage import zoom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSCITEmRkbT1"
      },
      "source": [
        "input = \"drive/MyDrive/Grayscale_Colorize/test_input\"\n",
        "output = \"drive/MyDrive/Grayscale_Colorize/test_output\"\n",
        "model = \"drive/MyDrive/Grayscale_Colorize/G_Final.pth\"\n",
        "gpu = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJJXpJQWFN2D"
      },
      "source": [
        "G = generator()\n",
        "\n",
        "if gpu>=0:\n",
        "    G=G.cuda(gpu)\n",
        "    G.load_state_dict(torch.load(model,map_location='cuda:0'))\n",
        "else:\n",
        "    G.load_state_dict(torch.load(model,map_location={'cuda:1': 'cpu'}))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3q0FG_tGKiu"
      },
      "source": [
        "def inference(G,in_path,out_path):\n",
        "    p=Image.open(in_path).convert('RGB')\n",
        "    img_yuv = rgb2yuv(p)\n",
        "    H,W,_ = img_yuv.shape\n",
        "    infimg = np.expand_dims(np.expand_dims(img_yuv[...,0], axis=0), axis=0)\n",
        "    img_variable = Variable(torch.Tensor(infimg-0.5))\n",
        "    if gpu>=0:\n",
        "        img_variable=img_variable.cuda(gpu)\n",
        "    res = G(img_variable)\n",
        "    uv=res.cpu().detach().numpy()\n",
        "    uv[:,0,:,:] *= 0.436\n",
        "    uv[:,1,:,:] *= 0.615\n",
        "    (_,_,H1,W1) = uv.shape\n",
        "    uv = zoom(uv,(1,1,H/H1,W/W1))\n",
        "    yuv = np.concatenate([infimg,uv],axis=1)[0]\n",
        "    rgb=yuv2rgb(yuv.transpose(1,2,0))\n",
        "    cv2.imwrite(out_path,(rgb.clip(min=0,max=1)*256)[:,:,[2,1,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNb7FHnVGdsk"
      },
      "source": [
        "if not os.path.isdir(input):\n",
        "    inference(G, input, output)\n",
        "else:\n",
        "    if not os.path.exists(output):\n",
        "        os.makedirs(output)\n",
        "    for f in os.listdir(input):\n",
        "        inference(G,os.path.join(input, f), os.path.join(output, f))\n",
        "        print(\"DONE\", os.path.join(output, f))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}